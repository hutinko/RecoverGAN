{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier based on Inception and Tensorflow Slim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models import dataset_utils\n",
    "from models import imagenet\n",
    "from models import inception_preprocessing\n",
    "from models import inception_v4 as inception\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from urllib.request import urlopen\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inceptionv4_classifier(object):\n",
    "    def __init__(self, extension='.jpg', path_to_validate='to_validate/', checkpoints_dir='checkpoints/', keyword='cat', top_k = 5):\n",
    "        self.slim = tf.contrib.slim\n",
    "        self.model_url = \"http://download.tensorflow.org/models/inception_v4_2016_09_09.tar.gz\"\n",
    "        if not tf.gfile.Exists(checkpoints_dir):\n",
    "            tf.gfile.MakeDirs(checkpoints_dir)\n",
    "        self.checkpoints_dir = checkpoints_dir\n",
    "        if not tf.gfile.Exists(checkpoints_dir + 'inception_v4_2016_09_09.tar.gz'):\n",
    "            dataset_utils.download_and_uncompress_tarball(url, checkpoints_dir)\n",
    "            \n",
    "        self.image_size = inception.inception_v4.default_image_size\n",
    "        self.extension = extension\n",
    "        self.path_to_validate = path_to_validate\n",
    "        self.files = [filename for filename in glob.glob(self.path_to_validate + '*' + self.extension)]\n",
    "        self.dim = len(self.files)\n",
    "        print('Total files to perform validation: ' + str(self.dim))\n",
    "        \n",
    "        self.image_and_probabilities = []\n",
    "        self.keyword = keyword\n",
    "        self.top_k = top_k\n",
    "        self.accuracy = 0\n",
    "    \n",
    "    def image_preprocessor(self, img):\n",
    "        img_str = urlopen('file:' + urllib.request.pathname2url(img)).read()\n",
    "        image = tf.image.decode_jpeg(img_str, channels=3)\n",
    "        processed_image = inception_preprocessing.preprocess_image(image, self.image_size, self.image_size, is_training=False)\n",
    "        processed_images  = tf.expand_dims(processed_image, 0)\n",
    "        # return a tuple of (tensor, tensor)\n",
    "        return image, processed_images\n",
    "   \n",
    "    def main(self):\n",
    "        \n",
    "        with tf.Graph().as_default():\n",
    "            self.processed_tensor_list = map(self.image_preprocessor, self.files)\n",
    "                        \n",
    "            # Iterate over a map object\n",
    "            for tensor_tuple in self.processed_tensor_list:\n",
    "                \n",
    "                # Create the model, use the default arg scope to configure the batch norm parameters.\n",
    "                with self.slim.arg_scope(inception.inception_v4_arg_scope()):\n",
    "                    logits, _ = inception.inception_v4(tensor_tuple[1], num_classes=1001, is_training=False)\n",
    "                # Append a tuple (image, probability)\n",
    "                self.image_and_probabilities.append( (tensor_tuple[0],tf.nn.softmax(logits)) )\n",
    "            \n",
    "            self.init_fn = self.slim.assign_from_checkpoint_fn(\n",
    "                        os.path.join(self.checkpoints_dir, 'inception_v4.ckpt'),\n",
    "                        self.slim.get_model_variables('InceptionV4'))\n",
    "            \n",
    "            with tf.Session() as sess:\n",
    "                self.init_fn(sess)\n",
    "                for idx in range(self.dim):\n",
    "                    print('Classifying on image' + str(idx))\n",
    "                    _, probabilities = sess.run([self.image_and_probabilities[idx][0], self.image_and_probabilities[idx][1]])\n",
    "                    probabilities = probabilities[0, 0:]\n",
    "                    sorted_inds = [i[0] for i in sorted(enumerate(-probabilities), key=lambda x:x[1])]\n",
    "\n",
    "                    names = imagenet.create_readable_names_for_imagenet_labels()\n",
    "\n",
    "                    temp_array=[]\n",
    "                    for i in range(self.top_k):\n",
    "                        index = sorted_inds[i]\n",
    "                        temp_array.append(names[index])\n",
    "                        if self.keyword in temp_array:\n",
    "                            self.accuracy += 1\n",
    "                        print('Probability %0.2f%% => [%s]' % (probabilities[index], names[index]))\n",
    "        print('Classification Accuracy ====>' + str(tf.divide(self.accuracy,self.dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files to perform validation: 6\n",
      "Classifying on image0\n",
      "Probability 0.81% => [tiger, Panthera tigris]\n",
      "Probability 0.09% => [tiger cat]\n",
      "Probability 0.00% => [jaguar, panther, Panthera onca, Felis onca]\n",
      "Probability 0.00% => [lynx, catamount]\n",
      "Probability 0.00% => [leopard, Panthera pardus]\n",
      "Classifying on image1\n",
      "Probability 0.87% => [lion, king of beasts, Panthera leo]\n",
      "Probability 0.00% => [accordion, piano accordion, squeeze box]\n",
      "Probability 0.00% => [cougar, puma, catamount, mountain lion, painter, panther, Felis concolor]\n",
      "Probability 0.00% => [leopard, Panthera pardus]\n",
      "Probability 0.00% => [zebra]\n",
      "Classifying on image2\n",
      "Probability 0.91% => [fox squirrel, eastern fox squirrel, Sciurus niger]\n",
      "Probability 0.02% => [corn]\n",
      "Probability 0.02% => [ear, spike, capitulum]\n",
      "Probability 0.00% => [worm fence, snake fence, snake-rail fence, Virginia fence]\n",
      "Probability 0.00% => [acorn]\n",
      "Classifying on image3\n",
      "Probability 0.53% => [daisy]\n",
      "Probability 0.01% => [bee]\n",
      "Probability 0.01% => [vase]\n",
      "Probability 0.01% => [sulphur butterfly, sulfur butterfly]\n",
      "Probability 0.01% => [cabbage butterfly]\n",
      "Classifying on image4\n",
      "Probability 0.68% => [chow, chow chow]\n",
      "Probability 0.02% => [bull mastiff]\n",
      "Probability 0.02% => [French bulldog]\n",
      "Probability 0.01% => [pug, pug-dog]\n",
      "Probability 0.01% => [Brabancon griffon]\n",
      "Classifying on image5\n",
      "Probability 0.91% => [hare]\n",
      "Probability 0.04% => [wood rabbit, cottontail, cottontail rabbit]\n",
      "Probability 0.00% => [Angora, Angora rabbit]\n",
      "Probability 0.00% => [hook, claw]\n",
      "Probability 0.00% => [mud turtle]\n",
      "Classification Accuracy ====>0.0\n"
     ]
    }
   ],
   "source": [
    "app = inceptionv4_classifier()\n",
    "app.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
